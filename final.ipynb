{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebr\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/training.csv\n",
      "./data/testing.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LP001014</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LP001018</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LP001020</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "5  LP001011   Male     Yes          2      Graduate           Yes   \n",
       "6  LP001013   Male     Yes          0  Not Graduate            No   \n",
       "7  LP001014   Male     Yes         3+      Graduate            No   \n",
       "8  LP001018   Male     Yes          2      Graduate            No   \n",
       "9  LP001020   Male     Yes          1      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "5             5417             4196.0       267.0             360.0   \n",
       "6             2333             1516.0        95.0             360.0   \n",
       "7             3036             2504.0       158.0             360.0   \n",
       "8             4006             1526.0       168.0             360.0   \n",
       "9            12841            10968.0       349.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  \n",
       "5             1.0         Urban           Y  \n",
       "6             1.0         Urban           Y  \n",
       "7             0.0     Semiurban           N  \n",
       "8             1.0         Urban           Y  \n",
       "9             1.0     Semiurban           N  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv('./data/training.csv')\n",
    "testing_df = pd.read_csv('./data/testing.csv')\n",
    "\n",
    "training_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2340</td>\n",
       "      <td>2546</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2165</td>\n",
       "      <td>3422</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2226</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3881</td>\n",
       "      <td>0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13633</td>\n",
       "      <td>0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>123.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "0    Male     Yes          0      Graduate            No             5720   \n",
       "1    Male     Yes          1      Graduate            No             3076   \n",
       "2    Male     Yes          2      Graduate            No             5000   \n",
       "3    Male     Yes          2      Graduate            No             2340   \n",
       "4    Male      No          0  Not Graduate            No             3276   \n",
       "5    Male     Yes          0  Not Graduate           Yes             2165   \n",
       "6  Female      No          1  Not Graduate            No             2226   \n",
       "7    Male     Yes          2  Not Graduate            No             3881   \n",
       "8    Male     Yes          2      Graduate           NaN            13633   \n",
       "9    Male      No          0  Not Graduate            No             2400   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0       110.0             360.0             1.0   \n",
       "1               1500       126.0             360.0             1.0   \n",
       "2               1800       208.0             360.0             1.0   \n",
       "3               2546       100.0             360.0             NaN   \n",
       "4                  0        78.0             360.0             1.0   \n",
       "5               3422       152.0             360.0             1.0   \n",
       "6                  0        59.0             360.0             1.0   \n",
       "7                  0       147.0             360.0             0.0   \n",
       "8                  0       280.0             240.0             1.0   \n",
       "9               2400       123.0             360.0             1.0   \n",
       "\n",
       "  Property_Area  \n",
       "0         Urban  \n",
       "1         Urban  \n",
       "2         Urban  \n",
       "3         Urban  \n",
       "4         Urban  \n",
       "5         Urban  \n",
       "6     Semiurban  \n",
       "7         Rural  \n",
       "8         Urban  \n",
       "9     Semiurban  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.drop(labels='Loan_ID', axis=1, inplace=True)\n",
    "training_df.drop(labels='Loan_ID', axis=1, inplace=True)\n",
    "\n",
    "testing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_History       50\n",
       "Self_Employed        32\n",
       "LoanAmount           22\n",
       "Dependents           15\n",
       "Loan_Amount_Term     14\n",
       "Gender               13\n",
       "Married               3\n",
       "Education             0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vaiables: [ 1.  0. nan] \n",
      "\n",
      "dtype of Credit_History: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking unique variables and dtypes in Credit_History\n",
    "print(f\"Unique vaiables: {training_df['Credit_History'].unique()} \\n\\ndtype of Credit_History: {training_df['Credit_History'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the Credit_History column to the object datatype\n",
    "training_df['Credit_History'] = training_df['Credit_History'].astype('object')\n",
    "training_df['Credit_History'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Credit_History with mode: 1.0\n",
      "Imputed Self_Employed with mode: No\n",
      "Imputed LoanAmount with mean: 146.41216216216216\n",
      "Imputed Dependents with mode: 0\n",
      "Imputed Loan_Amount_Term with mean: 342.0\n",
      "Imputed Gender with mode: Male\n",
      "Imputed Married with mode: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/g9zgyyn94013vflzxszd6d840000gn/T/ipykernel_42553/1121847353.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  training_df[col].fillna(mode_value, inplace=True)\n",
      "/var/folders/k1/g9zgyyn94013vflzxszd6d840000gn/T/ipykernel_42553/1121847353.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  training_df[col].fillna(mode_value, inplace=True)\n",
      "/var/folders/k1/g9zgyyn94013vflzxszd6d840000gn/T/ipykernel_42553/1121847353.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  training_df[col].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# List of columns with missing values\n",
    "null_cols = ['Credit_History', 'Self_Employed', 'LoanAmount', 'Dependents', 'Loan_Amount_Term', 'Gender', 'Married']\n",
    "\n",
    "# Imputation loop\n",
    "for col in null_cols:\n",
    "    if training_df[col].dtype == 'object':\n",
    "        # Impute categorical variables with mode (most frequent value in the dataset)\n",
    "        mode_value = training_df[col].mode()[0]\n",
    "        training_df[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Imputed {col} with mode: {mode_value}\")\n",
    "    else:\n",
    "        # Impute numerical variables with mean for non-binary, and mode for binary\n",
    "        mean_value = training_df[col].mean()\n",
    "        training_df[col].fillna(mean_value, inplace=True)\n",
    "        print(f\"Imputed {col} with mean: {mean_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we removed all the null values.\n",
    "training_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Gender             614 non-null    int64  \n",
      " 1   Married            614 non-null    int64  \n",
      " 2   Dependents         614 non-null    int64  \n",
      " 3   Education          614 non-null    int64  \n",
      " 4   Self_Employed      614 non-null    int64  \n",
      " 5   ApplicantIncome    614 non-null    int64  \n",
      " 6   CoapplicantIncome  614 non-null    float64\n",
      " 7   LoanAmount         614 non-null    float64\n",
      " 8   Loan_Amount_Term   614 non-null    float64\n",
      " 9   Credit_History     614 non-null    float64\n",
      " 10  Property_Area      614 non-null    int64  \n",
      " 11  Loan_Status        614 non-null    int64  \n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 57.7 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 367 entries, 0 to 366\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Gender             356 non-null    float64\n",
      " 1   Married            367 non-null    int64  \n",
      " 2   Dependents         357 non-null    float64\n",
      " 3   Education          367 non-null    int64  \n",
      " 4   Self_Employed      344 non-null    float64\n",
      " 5   ApplicantIncome    367 non-null    int64  \n",
      " 6   CoapplicantIncome  367 non-null    int64  \n",
      " 7   LoanAmount         362 non-null    float64\n",
      " 8   Loan_Amount_Term   361 non-null    float64\n",
      " 9   Credit_History     338 non-null    float64\n",
      " 10  Property_Area      367 non-null    int64  \n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 31.7 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/g9zgyyn94013vflzxszd6d840000gn/T/ipykernel_42553/30875967.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  training_df.replace(label_mapping, inplace=True)\n",
      "/var/folders/k1/g9zgyyn94013vflzxszd6d840000gn/T/ipykernel_42553/30875967.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  testing_df.replace(label_mapping, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Mapping Categorical values\n",
    "\n",
    "label_mapping = {'Male': 1, 'Female': 0,\n",
    "'Yes': 1, 'No': 0,\n",
    "'0': 0, '1': 1, '2': 2, '3+': 3 ,\n",
    "'Graduate': 1, 'Not Graduate': 0,\n",
    "'Urban': 1, 'Semiurban': 2,'Rural': 3,\n",
    "'Y': 1, 'N': 0}\n",
    "\n",
    "# Apply label encoding to categorical columns \n",
    "training_df.replace(label_mapping, inplace=True)\n",
    "testing_df.replace(label_mapping, inplace=True)\n",
    "\n",
    "training_df.info()\n",
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364569</td>\n",
       "      <td>0.172914</td>\n",
       "      <td>-0.045364</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.107930</td>\n",
       "      <td>-0.073567</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.017987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.364569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334216</td>\n",
       "      <td>-0.012304</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.051708</td>\n",
       "      <td>0.075948</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>-0.100863</td>\n",
       "      <td>0.010938</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>0.091478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>0.172914</td>\n",
       "      <td>0.334216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055752</td>\n",
       "      <td>0.056798</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.163106</td>\n",
       "      <td>-0.101054</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.010118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>-0.045364</td>\n",
       "      <td>-0.012304</td>\n",
       "      <td>-0.055752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.140760</td>\n",
       "      <td>0.062290</td>\n",
       "      <td>0.166998</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>0.073658</td>\n",
       "      <td>-0.065243</td>\n",
       "      <td>0.085884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.056798</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127180</td>\n",
       "      <td>-0.016100</td>\n",
       "      <td>0.115260</td>\n",
       "      <td>-0.033943</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>-0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.051708</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>0.140760</td>\n",
       "      <td>0.127180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116605</td>\n",
       "      <td>0.565620</td>\n",
       "      <td>-0.045242</td>\n",
       "      <td>-0.018615</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.004710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.075948</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.062290</td>\n",
       "      <td>-0.016100</td>\n",
       "      <td>-0.116605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187828</td>\n",
       "      <td>-0.059675</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>-0.010522</td>\n",
       "      <td>-0.059187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0.107930</td>\n",
       "      <td>0.147141</td>\n",
       "      <td>0.163106</td>\n",
       "      <td>0.166998</td>\n",
       "      <td>0.115260</td>\n",
       "      <td>0.565620</td>\n",
       "      <td>0.187828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.036416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>-0.073567</td>\n",
       "      <td>-0.100863</td>\n",
       "      <td>-0.101054</td>\n",
       "      <td>0.077242</td>\n",
       "      <td>-0.033943</td>\n",
       "      <td>-0.045242</td>\n",
       "      <td>-0.059675</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.020974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.010938</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>0.073658</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>-0.018615</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.540556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>0.025752</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.065243</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.010522</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <td>0.017987</td>\n",
       "      <td>0.091478</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.085884</td>\n",
       "      <td>-0.003700</td>\n",
       "      <td>-0.004710</td>\n",
       "      <td>-0.059187</td>\n",
       "      <td>-0.036416</td>\n",
       "      <td>-0.020974</td>\n",
       "      <td>0.540556</td>\n",
       "      <td>-0.032112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gender   Married  Dependents  Education  Self_Employed  \\\n",
       "Gender             1.000000  0.364569    0.172914  -0.045364      -0.000525   \n",
       "Married            0.364569  1.000000    0.334216  -0.012304       0.004489   \n",
       "Dependents         0.172914  0.334216    1.000000  -0.055752       0.056798   \n",
       "Education         -0.045364 -0.012304   -0.055752   1.000000       0.010383   \n",
       "Self_Employed     -0.000525  0.004489    0.056798   0.010383       1.000000   \n",
       "ApplicantIncome    0.058809  0.051708    0.118202   0.140760       0.127180   \n",
       "CoapplicantIncome  0.082912  0.075948    0.030430   0.062290      -0.016100   \n",
       "LoanAmount         0.107930  0.147141    0.163106   0.166998       0.115260   \n",
       "Loan_Amount_Term  -0.073567 -0.100863   -0.101054   0.077242      -0.033943   \n",
       "Credit_History     0.009170  0.010938   -0.040160   0.073658      -0.001550   \n",
       "Property_Area      0.025752 -0.004257    0.000244  -0.065243       0.030860   \n",
       "Loan_Status        0.017987  0.091478    0.010118   0.085884      -0.003700   \n",
       "\n",
       "                   ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "Gender                    0.058809           0.082912    0.107930   \n",
       "Married                   0.051708           0.075948    0.147141   \n",
       "Dependents                0.118202           0.030430    0.163106   \n",
       "Education                 0.140760           0.062290    0.166998   \n",
       "Self_Employed             0.127180          -0.016100    0.115260   \n",
       "ApplicantIncome           1.000000          -0.116605    0.565620   \n",
       "CoapplicantIncome        -0.116605           1.000000    0.187828   \n",
       "LoanAmount                0.565620           0.187828    1.000000   \n",
       "Loan_Amount_Term         -0.045242          -0.059675    0.038801   \n",
       "Credit_History           -0.018615           0.011134   -0.001431   \n",
       "Property_Area             0.009500          -0.010522    0.044776   \n",
       "Loan_Status              -0.004710          -0.059187   -0.036416   \n",
       "\n",
       "                   Loan_Amount_Term  Credit_History  Property_Area  \\\n",
       "Gender                    -0.073567        0.009170       0.025752   \n",
       "Married                   -0.100863        0.010938      -0.004257   \n",
       "Dependents                -0.101054       -0.040160       0.000244   \n",
       "Education                  0.077242        0.073658      -0.065243   \n",
       "Self_Employed             -0.033943       -0.001550       0.030860   \n",
       "ApplicantIncome           -0.045242       -0.018615       0.009500   \n",
       "CoapplicantIncome         -0.059675        0.011134      -0.010522   \n",
       "LoanAmount                 0.038801       -0.001431       0.044776   \n",
       "Loan_Amount_Term           1.000000        0.000432       0.077620   \n",
       "Credit_History             0.000432        1.000000      -0.001963   \n",
       "Property_Area              0.077620       -0.001963       1.000000   \n",
       "Loan_Status               -0.020974        0.540556      -0.032112   \n",
       "\n",
       "                   Loan_Status  \n",
       "Gender                0.017987  \n",
       "Married               0.091478  \n",
       "Dependents            0.010118  \n",
       "Education             0.085884  \n",
       "Self_Employed        -0.003700  \n",
       "ApplicantIncome      -0.004710  \n",
       "CoapplicantIncome    -0.059187  \n",
       "LoanAmount           -0.036416  \n",
       "Loan_Amount_Term     -0.020974  \n",
       "Credit_History        0.540556  \n",
       "Property_Area        -0.032112  \n",
       "Loan_Status           1.000000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a correlation between the training dataset\n",
    "corr_matrix = training_df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_df['Loan_Status']\n",
    "x = training_df.drop('Loan_Status', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49617829,  0.73429214, -0.72293243, ...,  0.27725281,\n",
       "         0.39751587,  0.06390164],\n",
       "       [ 0.49617829, -1.36185578,  2.26830204, ...,  0.27725281,\n",
       "         0.39751587,  1.31892981],\n",
       "       [ 0.49617829,  0.73429214,  0.27414573, ...,  0.27725281,\n",
       "         0.39751587,  1.31892981],\n",
       "       ...,\n",
       "       [ 0.49617829, -1.36185578,  1.27122388, ...,  0.27725281,\n",
       "         0.39751587,  0.06390164],\n",
       "       [ 0.49617829, -1.36185578, -0.72293243, ...,  0.27725281,\n",
       "         0.39751587,  1.31892981],\n",
       "       [ 0.49617829,  0.73429214, -0.72293243, ...,  0.27725281,\n",
       "         0.39751587,  1.31892981]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 0.7810 - val_accuracy: 0.5203 - val_loss: 0.8019\n",
      "Epoch 2/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.8461 - val_accuracy: 0.5366 - val_loss: 0.7966\n",
      "Epoch 3/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.7640 - val_accuracy: 0.5528 - val_loss: 0.7910\n",
      "Epoch 4/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5454 - loss: 0.7891 - val_accuracy: 0.5610 - val_loss: 0.7857\n",
      "Epoch 5/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 0.7830 - val_accuracy: 0.5610 - val_loss: 0.7800\n",
      "Epoch 6/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 0.7592 - val_accuracy: 0.5772 - val_loss: 0.7743\n",
      "Epoch 7/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5717 - loss: 0.7504 - val_accuracy: 0.5935 - val_loss: 0.7687\n",
      "Epoch 8/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.7597 - val_accuracy: 0.5935 - val_loss: 0.7633\n",
      "Epoch 9/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.7265 - val_accuracy: 0.6179 - val_loss: 0.7577\n",
      "Epoch 10/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6261 - loss: 0.7319 - val_accuracy: 0.6098 - val_loss: 0.7522\n",
      "Epoch 11/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.7241 - val_accuracy: 0.6098 - val_loss: 0.7468\n",
      "Epoch 12/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6395 - loss: 0.7104 - val_accuracy: 0.6179 - val_loss: 0.7411\n",
      "Epoch 13/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6623 - loss: 0.7234 - val_accuracy: 0.6341 - val_loss: 0.7356\n",
      "Epoch 14/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6499 - loss: 0.7158 - val_accuracy: 0.6423 - val_loss: 0.7300\n",
      "Epoch 15/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6762 - loss: 0.6921 - val_accuracy: 0.6423 - val_loss: 0.7250\n",
      "Epoch 16/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.7267 - val_accuracy: 0.6585 - val_loss: 0.7198\n",
      "Epoch 17/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.7052 - val_accuracy: 0.6667 - val_loss: 0.7144\n",
      "Epoch 18/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.7002 - val_accuracy: 0.6829 - val_loss: 0.7092\n",
      "Epoch 19/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6891 - val_accuracy: 0.6992 - val_loss: 0.7041\n",
      "Epoch 20/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6859 - val_accuracy: 0.6992 - val_loss: 0.6990\n",
      "Epoch 21/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.7114 - val_accuracy: 0.7073 - val_loss: 0.6942\n",
      "Epoch 22/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.6919 - val_accuracy: 0.7154 - val_loss: 0.6893\n",
      "Epoch 23/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.6861 - val_accuracy: 0.7154 - val_loss: 0.6844\n",
      "Epoch 24/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7767 - loss: 0.6274 - val_accuracy: 0.7154 - val_loss: 0.6796\n",
      "Epoch 25/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.6313 - val_accuracy: 0.7236 - val_loss: 0.6750\n",
      "Epoch 26/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.6307 - val_accuracy: 0.7317 - val_loss: 0.6707\n",
      "Epoch 27/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7729 - loss: 0.6591 - val_accuracy: 0.7398 - val_loss: 0.6663\n",
      "Epoch 28/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.6073 - val_accuracy: 0.7398 - val_loss: 0.6617\n",
      "Epoch 29/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.6434 - val_accuracy: 0.7317 - val_loss: 0.6574\n",
      "Epoch 30/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.6327 - val_accuracy: 0.7317 - val_loss: 0.6532\n",
      "Epoch 31/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.6658 - val_accuracy: 0.7398 - val_loss: 0.6494\n",
      "Epoch 32/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.6034 - val_accuracy: 0.7398 - val_loss: 0.6453\n",
      "Epoch 33/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.6399 - val_accuracy: 0.7398 - val_loss: 0.6413\n",
      "Epoch 34/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.6348 - val_accuracy: 0.7561 - val_loss: 0.6375\n",
      "Epoch 35/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.6128 - val_accuracy: 0.7724 - val_loss: 0.6338\n",
      "Epoch 36/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5941 - val_accuracy: 0.7967 - val_loss: 0.6302\n",
      "Epoch 37/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.6139 - val_accuracy: 0.8049 - val_loss: 0.6267\n",
      "Epoch 38/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.5859 - val_accuracy: 0.8049 - val_loss: 0.6235\n",
      "Epoch 39/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.6194 - val_accuracy: 0.8049 - val_loss: 0.6200\n",
      "Epoch 40/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.6317 - val_accuracy: 0.8049 - val_loss: 0.6167\n",
      "Epoch 41/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.5809 - val_accuracy: 0.8049 - val_loss: 0.6135\n",
      "Epoch 42/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.5891 - val_accuracy: 0.8049 - val_loss: 0.6103\n",
      "Epoch 43/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.5685 - val_accuracy: 0.8049 - val_loss: 0.6074\n",
      "Epoch 44/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.6119 - val_accuracy: 0.8130 - val_loss: 0.6044\n",
      "Epoch 45/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7929 - loss: 0.6039 - val_accuracy: 0.8130 - val_loss: 0.6015\n",
      "Epoch 46/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.5961 - val_accuracy: 0.8130 - val_loss: 0.5987\n",
      "Epoch 47/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.5657 - val_accuracy: 0.8130 - val_loss: 0.5960\n",
      "Epoch 48/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.6271 - val_accuracy: 0.8130 - val_loss: 0.5933\n",
      "Epoch 49/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.5730 - val_accuracy: 0.8211 - val_loss: 0.5906\n",
      "Epoch 50/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.5837 - val_accuracy: 0.8211 - val_loss: 0.5882\n",
      "Epoch 51/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.5693 - val_accuracy: 0.8211 - val_loss: 0.5857\n",
      "Epoch 52/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.5723 - val_accuracy: 0.8211 - val_loss: 0.5833\n",
      "Epoch 53/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.5886 - val_accuracy: 0.8211 - val_loss: 0.5809\n",
      "Epoch 54/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.5918 - val_accuracy: 0.8211 - val_loss: 0.5787\n",
      "Epoch 55/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.6342 - val_accuracy: 0.8211 - val_loss: 0.5765\n",
      "Epoch 56/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.5469 - val_accuracy: 0.8211 - val_loss: 0.5743\n",
      "Epoch 57/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.5725 - val_accuracy: 0.8293 - val_loss: 0.5722\n",
      "Epoch 58/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.6109 - val_accuracy: 0.8293 - val_loss: 0.5701\n",
      "Epoch 59/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.5842 - val_accuracy: 0.8293 - val_loss: 0.5682\n",
      "Epoch 60/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.5277 - val_accuracy: 0.8374 - val_loss: 0.5662\n",
      "Epoch 61/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.5396 - val_accuracy: 0.8374 - val_loss: 0.5643\n",
      "Epoch 62/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.5211 - val_accuracy: 0.8374 - val_loss: 0.5625\n",
      "Epoch 63/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.5882 - val_accuracy: 0.8374 - val_loss: 0.5608\n",
      "Epoch 64/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.5549 - val_accuracy: 0.8374 - val_loss: 0.5590\n",
      "Epoch 65/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.5740 - val_accuracy: 0.8374 - val_loss: 0.5574\n",
      "Epoch 66/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.6003 - val_accuracy: 0.8374 - val_loss: 0.5558\n",
      "Epoch 67/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.5601 - val_accuracy: 0.8374 - val_loss: 0.5542\n",
      "Epoch 68/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.5836 - val_accuracy: 0.8374 - val_loss: 0.5526\n",
      "Epoch 69/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.5658 - val_accuracy: 0.8374 - val_loss: 0.5512\n",
      "Epoch 70/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.4943 - val_accuracy: 0.8374 - val_loss: 0.5497\n",
      "Epoch 71/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.5039 - val_accuracy: 0.8374 - val_loss: 0.5483\n",
      "Epoch 72/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.5614 - val_accuracy: 0.8374 - val_loss: 0.5470\n",
      "Epoch 73/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7921 - loss: 0.5552 - val_accuracy: 0.8374 - val_loss: 0.5457\n",
      "Epoch 74/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.5435 - val_accuracy: 0.8293 - val_loss: 0.5443\n",
      "Epoch 75/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.5376 - val_accuracy: 0.8293 - val_loss: 0.5431\n",
      "Epoch 76/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.5303 - val_accuracy: 0.8293 - val_loss: 0.5418\n",
      "Epoch 77/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.5494 - val_accuracy: 0.8293 - val_loss: 0.5406\n",
      "Epoch 78/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.5319 - val_accuracy: 0.8293 - val_loss: 0.5395\n",
      "Epoch 79/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.5011 - val_accuracy: 0.8293 - val_loss: 0.5384\n",
      "Epoch 80/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.5122 - val_accuracy: 0.8293 - val_loss: 0.5373\n",
      "Epoch 81/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.5366 - val_accuracy: 0.8293 - val_loss: 0.5363\n",
      "Epoch 82/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.5642 - val_accuracy: 0.8293 - val_loss: 0.5352\n",
      "Epoch 83/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.5844 - val_accuracy: 0.8293 - val_loss: 0.5342\n",
      "Epoch 84/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.4791 - val_accuracy: 0.8293 - val_loss: 0.5332\n",
      "Epoch 85/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.5155 - val_accuracy: 0.8293 - val_loss: 0.5323\n",
      "Epoch 86/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.5240 - val_accuracy: 0.8293 - val_loss: 0.5314\n",
      "Epoch 87/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.5826 - val_accuracy: 0.8293 - val_loss: 0.5305\n",
      "Epoch 88/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.5624 - val_accuracy: 0.8293 - val_loss: 0.5296\n",
      "Epoch 89/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.5452 - val_accuracy: 0.8293 - val_loss: 0.5287\n",
      "Epoch 90/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.5145 - val_accuracy: 0.8293 - val_loss: 0.5279\n",
      "Epoch 91/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.5497 - val_accuracy: 0.8293 - val_loss: 0.5271\n",
      "Epoch 92/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.5611 - val_accuracy: 0.8293 - val_loss: 0.5263\n",
      "Epoch 93/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.5417 - val_accuracy: 0.8293 - val_loss: 0.5255\n",
      "Epoch 94/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.5844 - val_accuracy: 0.8293 - val_loss: 0.5248\n",
      "Epoch 95/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.5590 - val_accuracy: 0.8293 - val_loss: 0.5240\n",
      "Epoch 96/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.5052 - val_accuracy: 0.8293 - val_loss: 0.5233\n",
      "Epoch 97/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.5307 - val_accuracy: 0.8293 - val_loss: 0.5226\n",
      "Epoch 98/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.5263 - val_accuracy: 0.8293 - val_loss: 0.5219\n",
      "Epoch 99/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4972 - val_accuracy: 0.8293 - val_loss: 0.5212\n",
      "Epoch 100/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4942 - val_accuracy: 0.8293 - val_loss: 0.5206\n",
      "Epoch 101/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4938 - val_accuracy: 0.8293 - val_loss: 0.5200\n",
      "Epoch 102/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.5678 - val_accuracy: 0.8293 - val_loss: 0.5194\n",
      "Epoch 103/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.5396 - val_accuracy: 0.8293 - val_loss: 0.5187\n",
      "Epoch 104/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4858 - val_accuracy: 0.8293 - val_loss: 0.5181\n",
      "Epoch 105/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.5049 - val_accuracy: 0.8293 - val_loss: 0.5176\n",
      "Epoch 106/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.5708 - val_accuracy: 0.8293 - val_loss: 0.5170\n",
      "Epoch 107/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8140 - loss: 0.5190 - val_accuracy: 0.8293 - val_loss: 0.5164\n",
      "Epoch 108/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.5757 - val_accuracy: 0.8293 - val_loss: 0.5159\n",
      "Epoch 109/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.5630 - val_accuracy: 0.8293 - val_loss: 0.5154\n",
      "Epoch 110/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.5291 - val_accuracy: 0.8293 - val_loss: 0.5149\n",
      "Epoch 111/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.5338 - val_accuracy: 0.8293 - val_loss: 0.5144\n",
      "Epoch 112/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.5883 - val_accuracy: 0.8293 - val_loss: 0.5139\n",
      "Epoch 113/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.5550 - val_accuracy: 0.8293 - val_loss: 0.5134\n",
      "Epoch 114/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.5078 - val_accuracy: 0.8293 - val_loss: 0.5129\n",
      "Epoch 115/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.4748 - val_accuracy: 0.8293 - val_loss: 0.5125\n",
      "Epoch 116/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.5200 - val_accuracy: 0.8293 - val_loss: 0.5120\n",
      "Epoch 117/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.5117 - val_accuracy: 0.8293 - val_loss: 0.5116\n",
      "Epoch 118/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4895 - val_accuracy: 0.8293 - val_loss: 0.5112\n",
      "Epoch 119/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.5453 - val_accuracy: 0.8293 - val_loss: 0.5108\n",
      "Epoch 120/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.5561 - val_accuracy: 0.8293 - val_loss: 0.5104\n",
      "Epoch 121/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.5510 - val_accuracy: 0.8293 - val_loss: 0.5100\n",
      "Epoch 122/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.5322 - val_accuracy: 0.8293 - val_loss: 0.5096\n",
      "Epoch 123/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.5649 - val_accuracy: 0.8293 - val_loss: 0.5092\n",
      "Epoch 124/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.5123 - val_accuracy: 0.8293 - val_loss: 0.5088\n",
      "Epoch 125/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4899 - val_accuracy: 0.8293 - val_loss: 0.5085\n",
      "Epoch 126/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.5245 - val_accuracy: 0.8293 - val_loss: 0.5081\n",
      "Epoch 127/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.5495 - val_accuracy: 0.8293 - val_loss: 0.5077\n",
      "Epoch 128/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.5231 - val_accuracy: 0.8293 - val_loss: 0.5074\n",
      "Epoch 129/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.5437 - val_accuracy: 0.8293 - val_loss: 0.5071\n",
      "Epoch 130/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.5260 - val_accuracy: 0.8293 - val_loss: 0.5068\n",
      "Epoch 131/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.5205 - val_accuracy: 0.8293 - val_loss: 0.5064\n",
      "Epoch 132/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.5050 - val_accuracy: 0.8293 - val_loss: 0.5061\n",
      "Epoch 133/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4897 - val_accuracy: 0.8293 - val_loss: 0.5058\n",
      "Epoch 134/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.5684 - val_accuracy: 0.8293 - val_loss: 0.5055\n",
      "Epoch 135/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.5212 - val_accuracy: 0.8293 - val_loss: 0.5052\n",
      "Epoch 136/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.5552 - val_accuracy: 0.8293 - val_loss: 0.5049\n",
      "Epoch 137/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4932 - val_accuracy: 0.8293 - val_loss: 0.5046\n",
      "Epoch 138/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.5016 - val_accuracy: 0.8293 - val_loss: 0.5044\n",
      "Epoch 139/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4938 - val_accuracy: 0.8293 - val_loss: 0.5041\n",
      "Epoch 140/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.5321 - val_accuracy: 0.8293 - val_loss: 0.5038\n",
      "Epoch 141/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.5511 - val_accuracy: 0.8293 - val_loss: 0.5036\n",
      "Epoch 142/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.5520 - val_accuracy: 0.8293 - val_loss: 0.5033\n",
      "Epoch 143/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4842 - val_accuracy: 0.8293 - val_loss: 0.5030\n",
      "Epoch 144/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4732 - val_accuracy: 0.8293 - val_loss: 0.5028\n",
      "Epoch 145/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.4375 - val_accuracy: 0.8293 - val_loss: 0.5026\n",
      "Epoch 146/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.5317 - val_accuracy: 0.8293 - val_loss: 0.5023\n",
      "Epoch 147/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.5465 - val_accuracy: 0.8293 - val_loss: 0.5021\n",
      "Epoch 148/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.4936 - val_accuracy: 0.8293 - val_loss: 0.5019\n",
      "Epoch 149/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.5006 - val_accuracy: 0.8293 - val_loss: 0.5017\n",
      "Epoch 150/150\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4620 - val_accuracy: 0.8293 - val_loss: 0.5015\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4838 \n",
      "Loss: 0.5014520883560181\n",
      "Accuracy: 0.8292682766914368\n"
     ]
    }
   ],
   "source": [
    "# Define logistic regression model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='nadam', loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=16, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
